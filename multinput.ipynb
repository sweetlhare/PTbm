{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipypb\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import ast\n",
    "from ipypb import track\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('dataset_train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     947\n",
       "3     851\n",
       "10    611\n",
       "11    544\n",
       "9     504\n",
       "2     322\n",
       "8     284\n",
       "12    272\n",
       "7     150\n",
       "6      66\n",
       "1      53\n",
       "5      41\n",
       "13     32\n",
       "14      8\n",
       "Name: Question, dtype: int64"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Filename', 'Test_index', 'Presentation']).Question.count().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Data = train.Data.apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "train.Data_2 = train.Data_2.apply(lambda x: np.array(ast.literal_eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(['Filename', 'Test_index', 'Presentation', 'Question']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['idx'] = list(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31383 entries, 0 to 31382\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Filename      31383 non-null  object\n",
      " 1   Test_index    31383 non-null  int64 \n",
      " 2   Presentation  31383 non-null  int64 \n",
      " 3   Question      31383 non-null  int64 \n",
      " 4   Data          31383 non-null  object\n",
      " 5   Data_2        31383 non-null  object\n",
      " 6   Class_label   31383 non-null  int64 \n",
      " 7   idx           31383 non-null  int64 \n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x692ead9d0>]"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train.Data_2.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x6aa597910>]"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.abs(train.Data_2.iloc[0] - train.Data_2.iloc[0].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = train.groupby(['Filename', 'Test_index', 'Presentation']).idx.unique().reset_index()\n",
    "train_sequences_labels = []\n",
    "\n",
    "for i in range(train_sequences.shape[0]):\n",
    "    train_sequences_labels.append(train.loc[train_sequences.idx[i], 'Class_label'].values)\n",
    "    \n",
    "train_sequences['labels'] = train_sequences_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"4685\" value=\"4685\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">0/4685</span>\n",
       "<span class=\"Time-label\">[00:00<00:00, 0.00s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [] 4685/4685 [00:00<00:00, 0.00s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idxs = []\n",
    "sample_labels = []\n",
    "\n",
    "for i in track(range(train_sequences.shape[0])):\n",
    "    indexes_ = np.random.choice(len(train_sequences.idx.iloc[i]), 3)\n",
    "    sample_idxs.append(train_sequences.idx.iloc[i][indexes_])\n",
    "    sample_labels.append(train_sequences.labels.iloc[i][indexes_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_labels = np.concatenate(sample_labels).reshape((len(sample_labels), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# balanced train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17642\n",
       "2     7028\n",
       "0     6713\n",
       "Name: Class_label, dtype: int64"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Class_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train = pd.concat([train[train.Class_label.isin([0, 2])],\n",
    "                            train[train.Class_label == 1].sample(7000)], ignore_index=True)\n",
    "\n",
    "balanced_train['idx'] = list(balanced_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    7028\n",
       "1    7000\n",
       "0    6713\n",
       "Name: Class_label, dtype: int64"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_train.Class_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train['Data_max'] = balanced_train.Data.apply(lambda x: np.max(x))\n",
    "balanced_train['Data_min'] = balanced_train.Data.apply(lambda x: np.min(x))\n",
    "balanced_train['Data_2_max'] = balanced_train.Data_2.apply(lambda x: np.max(x) if len(x) > 0 else 0)\n",
    "balanced_train['Data_2_min'] = balanced_train.Data_2.apply(lambda x: np.min(x) if len(x) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train = pd.merge(balanced_train.drop(['Data_max'], axis=1), \n",
    "                          balanced_train.groupby(['Filename', 'Test_index', 'Presentation']).Data_max.max().reset_index(), \n",
    "                          on=list(balanced_train.columns[:3]), how='left')\n",
    "\n",
    "balanced_train = pd.merge(balanced_train.drop(['Data_min'], axis=1), \n",
    "                          balanced_train.groupby(['Filename', 'Test_index', 'Presentation']).Data_min.min().reset_index(), \n",
    "                          on=list(balanced_train.columns[:3]), how='left')\n",
    "\n",
    "balanced_train = pd.merge(balanced_train.drop(['Data_2_max'], axis=1), \n",
    "                          balanced_train.groupby(['Filename', 'Test_index', 'Presentation']).Data_2_max.max().reset_index(), \n",
    "                          on=list(balanced_train.columns[:3]), how='left')\n",
    "\n",
    "balanced_train = pd.merge(balanced_train.drop(['Data_2_min'], axis=1), \n",
    "                          balanced_train.groupby(['Filename', 'Test_index', 'Presentation']).Data_2_min.min().reset_index(), \n",
    "                          on=list(balanced_train.columns[:3]), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Test_index</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>Question</th>\n",
       "      <th>Data</th>\n",
       "      <th>Data_2</th>\n",
       "      <th>Class_label</th>\n",
       "      <th>idx</th>\n",
       "      <th>Data_max</th>\n",
       "      <th>Data_min</th>\n",
       "      <th>Data_2_max</th>\n",
       "      <th>Data_2_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00b38188-82ee-4f1d-9661-485338815751</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[345, 357, 367, 377, 360, 217, 150, 180, 216, ...</td>\n",
       "      <td>[362, 383, 407, 424, 364, 63, 16, 112, 190, 19...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>628</td>\n",
       "      <td>-484</td>\n",
       "      <td>615</td>\n",
       "      <td>-853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Filename  Test_index  Presentation  Question  \\\n",
       "0  00b38188-82ee-4f1d-9661-485338815751           0             1         1   \n",
       "\n",
       "                                                Data  \\\n",
       "0  [345, 357, 367, 377, 360, 217, 150, 180, 216, ...   \n",
       "\n",
       "                                              Data_2  Class_label  idx  \\\n",
       "0  [362, 383, 407, 424, 364, 63, 16, 112, 190, 19...            2    0   \n",
       "\n",
       "   Data_max  Data_min  Data_2_max  Data_2_min  \n",
       "0       628      -484         615        -853  "
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train['Data_max'] = balanced_train['Data_max'].max()\n",
    "balanced_train['Data_min'] = balanced_train['Data_min'].min()\n",
    "balanced_train['Data_2_max'] = balanced_train['Data_2_max'].max()\n",
    "balanced_train['Data_2_min'] = balanced_train['Data_2_min'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train['Data'] = balanced_train.apply(lambda x: (x[4] - x[9]) / (x[8] - x[9]), axis=1)\n",
    "balanced_train['Data_2'] = balanced_train.apply(lambda x: (x[5] - x[11]) / (x[10] - x[11]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"4685\" value=\"4685\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">0/4685</span>\n",
       "<span class=\"Time-label\">[00:00<00:00, 0.00s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [] 4685/4685 [00:00<00:00, 0.00s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"4685\" value=\"4685\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">0/4685</span>\n",
       "<span class=\"Time-label\">[00:00<00:00, 0.00s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [] 4685/4685 [00:00<00:00, 0.00s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neiro/miniforge3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/neiro/miniforge3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "for idx in track(sample_idxs):\n",
    "    temp = np.concatenate(train.Data.iloc[idx].values, axis=0)\n",
    "    if len(temp) < 720:\n",
    "        fill_temp = np.zeros((720-len(temp)))\n",
    "        fill_temp[...] = np.mean(temp)\n",
    "        temp = np.hstack([temp, fill_temp])\n",
    "    data1.append(temp)\n",
    "    \n",
    "data2 = []\n",
    "for idx in track(sample_idxs):\n",
    "    temp = np.concatenate(train.Data_2.iloc[idx].values, axis=0)\n",
    "    if len(temp) < 720:\n",
    "        fill_temp = np.zeros((720-len(temp)))\n",
    "        fill_temp[...] = np.mean(temp)\n",
    "        temp = np.hstack([temp, fill_temp])\n",
    "    data2.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.concatenate(data1).reshape((len(data1), 720))\n",
    "data2 = np.concatenate(data2).reshape((len(data1), 720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([data1[..., np.newaxis], data2[..., np.newaxis]], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sample_labels[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.concatenate([data1.to_numpy()[..., np.newaxis], \n",
    "#                        data2.to_numpy()[..., np.newaxis]], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_cumsum = np.cumsum(data1, axis=1)\n",
    "data2_cumsum = np.cumsum(data2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv_shifts = [3, 7, 15, 31, 63]\n",
    "derivs1 = []\n",
    "\n",
    "for ds in deriv_shifts:\n",
    "\n",
    "    deriv = data1[:, :-ds] - data1[:, ds:]\n",
    "    values_to_fill = data1.shape[1] - deriv.shape[1]\n",
    "    deriv = np.hstack([deriv, np.zeros((data1.shape[0], values_to_fill))])\n",
    "    \n",
    "    derivs1.append(deriv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv_shifts = [3, 7, 15, 31, 63]\n",
    "derivs2 = []\n",
    "\n",
    "for ds in deriv_shifts:\n",
    "\n",
    "    deriv = data2[:, :-ds] - data2[:, ds:]\n",
    "    values_to_fill = data2.shape[1] - deriv.shape[1]\n",
    "    deriv = np.hstack([deriv, np.zeros((data2.shape[0], values_to_fill))])\n",
    "    \n",
    "    derivs2.append(deriv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows = [3, 7, 15, 31, 63]\n",
    "\n",
    "# rolling_windows_sum_1 = []\n",
    "# rolling_windows_mean_1 = []\n",
    "# rolling_windows_max_1 = []\n",
    "# rolling_windows_min_1 = []\n",
    "\n",
    "# rolling_windows_sum_2 = []\n",
    "# rolling_windows_mean_2 = []\n",
    "# rolling_windows_max_2 = []\n",
    "# rolling_windows_min_2 = []\n",
    "\n",
    "# for window in track(windows):\n",
    "    \n",
    "#     rolling_windows_sum_1.append(data1.rolling(window, axis=1).sum().fillna(0).to_numpy())\n",
    "#     rolling_windows_mean_1.append(data1.rolling(window, axis=1).mean().fillna(0).to_numpy())\n",
    "#     rolling_windows_max_1.append(data1.rolling(window, axis=1).max().fillna(0).to_numpy())\n",
    "#     rolling_windows_min_1.append(data1.rolling(window, axis=1).min().fillna(0).to_numpy())\n",
    "    \n",
    "#     rolling_windows_sum_2.append(data2.rolling(window, axis=1).sum().fillna(0).to_numpy())\n",
    "#     rolling_windows_mean_2.append(data2.rolling(window, axis=1).mean().fillna(0).to_numpy())\n",
    "#     rolling_windows_max_2.append(data2.rolling(window, axis=1).max().fillna(0).to_numpy())\n",
    "#     rolling_windows_min_2.append(data2.rolling(window, axis=1).min().fillna(0).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([\n",
    "    data,\n",
    "    data1_cumsum[..., np.newaxis],\n",
    "    data2_cumsum[..., np.newaxis],\n",
    "], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "for deriv in derivs1:\n",
    "    data = np.concatenate([\n",
    "        data,\n",
    "        deriv[..., np.newaxis],\n",
    "    ], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "for deriv in derivs2:\n",
    "    data = np.concatenate([\n",
    "        data,\n",
    "        deriv[..., np.newaxis],\n",
    "    ], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rw_ in track([rolling_windows_sum_1, rolling_windows_mean_1, \n",
    "#                   rolling_windows_max_1, rolling_windows_min_1,\n",
    "#                   rolling_windows_sum_2, rolling_windows_mean_2,\n",
    "#                   rolling_windows_max_2, rolling_windows_min_2]):\n",
    "\n",
    "#     for rw in rw_:\n",
    "#         data = np.concatenate([\n",
    "#             data,\n",
    "#             rw[..., np.newaxis],\n",
    "#         ], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4685, 720, 14)"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# prepare data for pair-training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Filename', 'Presentation']).idx.count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Filename', 'Test_index', 'Presentation']).idx.shift(13).notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair1_ = []\n",
    "pair2_ = []\n",
    "\n",
    "labels_ = []\n",
    "\n",
    "for i in range(-13, 14, 1):\n",
    "    \n",
    "    if i != 0:\n",
    "    \n",
    "        temp = balanced_train.groupby(['Filename', 'Test_index', 'Presentation']).idx.shift(i)\n",
    "        \n",
    "        if temp.shape[0] > 0:\n",
    "            \n",
    "            pair1_.extend(list(balanced_train[temp.notnull()].idx))\n",
    "            pair2_.extend(list(temp[temp.notnull()].values))\n",
    "            \n",
    "            labels_.extend(list(balanced_train[temp.notnull()].Class_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pair1) == len(pair2) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair1 = np.array(pair1_, dtype=int)[:10000]\n",
    "pair2 = np.array(pair2_, dtype=int)[:10000]\n",
    "labels = np.array(labels_, dtype=int)[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# build 2 outputs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    \n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    \n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inp1 = keras.Input(shape=input_shape)\n",
    "    inp2 = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x12 = []\n",
    "    \n",
    "    for inputs in [inp1, inp2]:\n",
    "    \n",
    "        x = inputs\n",
    "        \n",
    "        x = layers.Conv1D(32, 3, activation='relu', input_shape=(240, 2))(x)\n",
    "        x = layers.Conv1D(16, 3, activation='relu')(x)\n",
    "        x = layers.Conv1D(8, 3, activation='relu')(x)\n",
    "        x = layers.AveragePooling1D()(x)\n",
    "        # x = layers.Flatten()(x)\n",
    "        \n",
    "        for _ in range(num_transformer_blocks):\n",
    "            x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "        x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "        x12.append(x)\n",
    "    \n",
    "    x = layers.concatenate(x12, axis=-1)\n",
    "    \n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    \n",
    "    output1 = layers.Dense(3, activation=\"softmax\", name='classification')(x)\n",
    "    output2 = layers.Dense(1, activation=\"softmax\", name='regression')(x)\n",
    "    \n",
    "    return keras.Model([inp1, inp2], [output1, output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_35 (InputLayer)          [(None, 240, 58)]    0           []                               \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)          [(None, 240, 58)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_322 (Conv1D)            (None, 238, 32)      5600        ['input_35[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_333 (Conv1D)            (None, 238, 32)      5600        ['input_36[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_323 (Conv1D)            (None, 236, 16)      1552        ['conv1d_322[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_334 (Conv1D)            (None, 236, 16)      1552        ['conv1d_333[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_324 (Conv1D)            (None, 234, 8)       392         ['conv1d_323[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_335 (Conv1D)            (None, 234, 8)       392         ['conv1d_334[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling1d_38 (AverageP  (None, 117, 8)      0           ['conv1d_324[0][0]']             \n",
      " ooling1D)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling1d_39 (AverageP  (None, 117, 8)      0           ['conv1d_335[0][0]']             \n",
      " ooling1D)                                                                                        \n",
      "                                                                                                  \n",
      " layer_normalization_275 (Layer  (None, 117, 8)      16          ['average_pooling1d_38[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " layer_normalization_283 (Layer  (None, 117, 8)      16          ['average_pooling1d_39[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_139 (Mult  (None, 117, 8)      35848       ['layer_normalization_275[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_143 (Mult  (None, 117, 8)      35848       ['layer_normalization_283[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_283[0][0]']\n",
      "                                                                                                  \n",
      " dropout_295 (Dropout)          (None, 117, 8)       0           ['multi_head_attention_139[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_303 (Dropout)          (None, 117, 8)       0           ['multi_head_attention_143[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_272 (TFOp  (None, 117, 8)      0           ['dropout_295[0][0]',            \n",
      " Lambda)                                                          'average_pooling1d_38[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_280 (TFOp  (None, 117, 8)      0           ['dropout_303[0][0]',            \n",
      " Lambda)                                                          'average_pooling1d_39[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_276 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_272[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_284 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_280[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_325 (Conv1D)            (None, 117, 4)       36          ['layer_normalization_276[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_336 (Conv1D)            (None, 117, 4)       36          ['layer_normalization_284[0][0]']\n",
      "                                                                                                  \n",
      " dropout_296 (Dropout)          (None, 117, 4)       0           ['conv1d_325[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_304 (Dropout)          (None, 117, 4)       0           ['conv1d_336[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_326 (Conv1D)            (None, 117, 8)       40          ['dropout_296[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_337 (Conv1D)            (None, 117, 8)       40          ['dropout_304[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_273 (TFOp  (None, 117, 8)      0           ['conv1d_326[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_272[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_281 (TFOp  (None, 117, 8)      0           ['conv1d_337[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_280[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_277 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_273[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_285 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_281[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_140 (Mult  (None, 117, 8)      35848       ['layer_normalization_277[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_277[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_144 (Mult  (None, 117, 8)      35848       ['layer_normalization_285[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_285[0][0]']\n",
      "                                                                                                  \n",
      " dropout_297 (Dropout)          (None, 117, 8)       0           ['multi_head_attention_140[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_305 (Dropout)          (None, 117, 8)       0           ['multi_head_attention_144[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_274 (TFOp  (None, 117, 8)      0           ['dropout_297[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_273[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_282 (TFOp  (None, 117, 8)      0           ['dropout_305[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_281[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_278 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_274[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_286 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_282[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_327 (Conv1D)            (None, 117, 4)       36          ['layer_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_338 (Conv1D)            (None, 117, 4)       36          ['layer_normalization_286[0][0]']\n",
      "                                                                                                  \n",
      " dropout_298 (Dropout)          (None, 117, 4)       0           ['conv1d_327[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_306 (Dropout)          (None, 117, 4)       0           ['conv1d_338[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_328 (Conv1D)            (None, 117, 8)       40          ['dropout_298[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_339 (Conv1D)            (None, 117, 8)       40          ['dropout_306[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_275 (TFOp  (None, 117, 8)      0           ['conv1d_328[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_274[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_283 (TFOp  (None, 117, 8)      0           ['conv1d_339[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_282[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_279 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_275[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_287 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_283[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_141 (Mult  (None, 117, 8)      35848       ['layer_normalization_279[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_279[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_145 (Mult  (None, 117, 8)      35848       ['layer_normalization_287[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_287[0][0]']\n",
      "                                                                                                  \n",
      " dropout_299 (Dropout)          (None, 117, 8)       0           ['multi_head_attention_141[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_307 (Dropout)          (None, 117, 8)       0           ['multi_head_attention_145[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_276 (TFOp  (None, 117, 8)      0           ['dropout_299[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_275[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_284 (TFOp  (None, 117, 8)      0           ['dropout_307[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_283[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_280 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_276[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_288 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_284[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_329 (Conv1D)            (None, 117, 4)       36          ['layer_normalization_280[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_340 (Conv1D)            (None, 117, 4)       36          ['layer_normalization_288[0][0]']\n",
      "                                                                                                  \n",
      " dropout_300 (Dropout)          (None, 117, 4)       0           ['conv1d_329[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_308 (Dropout)          (None, 117, 4)       0           ['conv1d_340[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_330 (Conv1D)            (None, 117, 8)       40          ['dropout_300[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_341 (Conv1D)            (None, 117, 8)       40          ['dropout_308[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_277 (TFOp  (None, 117, 8)      0           ['conv1d_330[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_276[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_285 (TFOp  (None, 117, 8)      0           ['conv1d_341[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_284[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_281 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_277[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_289 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_285[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_142 (Mult  (None, 117, 8)      35848       ['layer_normalization_281[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_281[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_146 (Mult  (None, 117, 8)      35848       ['layer_normalization_289[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_289[0][0]']\n",
      "                                                                                                  \n",
      " dropout_301 (Dropout)          (None, 117, 8)       0           ['multi_head_attention_142[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_309 (Dropout)          (None, 117, 8)       0           ['multi_head_attention_146[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_278 (TFOp  (None, 117, 8)      0           ['dropout_301[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_277[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_286 (TFOp  (None, 117, 8)      0           ['dropout_309[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_285[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_282 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_278[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_290 (Layer  (None, 117, 8)      16          ['tf.__operators__.add_286[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_331 (Conv1D)            (None, 117, 4)       36          ['layer_normalization_282[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_342 (Conv1D)            (None, 117, 4)       36          ['layer_normalization_290[0][0]']\n",
      "                                                                                                  \n",
      " dropout_302 (Dropout)          (None, 117, 4)       0           ['conv1d_331[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_310 (Dropout)          (None, 117, 4)       0           ['conv1d_342[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_332 (Conv1D)            (None, 117, 8)       40          ['dropout_302[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_343 (Conv1D)            (None, 117, 8)       40          ['dropout_310[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_279 (TFOp  (None, 117, 8)      0           ['conv1d_332[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_278[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_287 (TFOp  (None, 117, 8)      0           ['conv1d_343[0][0]',             \n",
      " Lambda)                                                          'tf.__operators__.add_286[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_34 (G  (None, 117)         0           ['tf.__operators__.add_279[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_35 (G  (None, 117)         0           ['tf.__operators__.add_287[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 234)          0           ['global_average_pooling1d_34[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_35[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 128)          30080       ['concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_311 (Dropout)          (None, 128)          0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " classification (Dense)         (None, 3)            387         ['dropout_311[0][0]']            \n",
      "                                                                                                  \n",
      " regression (Dense)             (None, 1)            129         ['dropout_311[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 333,332\n",
      "Trainable params: 333,332\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 19:31:35.724585: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - ETA: 0s - loss: 1.3183 - classification_loss: 0.9771 - regression_loss: 0.3412 - classification_sparse_categorical_accuracy: 0.5800 - regression_mean_absolute_error: 0.4863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 19:38:00.822026: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.29564, saving model to models/best.h5\n",
      "67/67 [==============================] - 421s 6s/step - loss: 1.3183 - classification_loss: 0.9771 - regression_loss: 0.3412 - classification_sparse_categorical_accuracy: 0.5800 - regression_mean_absolute_error: 0.4863 - val_loss: 1.2956 - val_classification_loss: 0.9575 - val_regression_loss: 0.3382 - val_classification_sparse_categorical_accuracy: 0.5900 - val_regression_mean_absolute_error: 0.4857 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3148 - classification_loss: 0.9736 - regression_loss: 0.3412 - classification_sparse_categorical_accuracy: 0.5805 - regression_mean_absolute_error: 0.4863\n",
      "Epoch 2: val_loss improved from 1.29564 to 1.29498, saving model to models/best.h5\n",
      "67/67 [==============================] - 350s 5s/step - loss: 1.3148 - classification_loss: 0.9736 - regression_loss: 0.3412 - classification_sparse_categorical_accuracy: 0.5805 - regression_mean_absolute_error: 0.4863 - val_loss: 1.2950 - val_classification_loss: 0.9568 - val_regression_loss: 0.3382 - val_classification_sparse_categorical_accuracy: 0.5900 - val_regression_mean_absolute_error: 0.4857 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      " 2/67 [..............................] - ETA: 5:50 - loss: 1.3098 - classification_loss: 0.9416 - regression_loss: 0.3682 - classification_sparse_categorical_accuracy: 0.6133 - regression_mean_absolute_error: 0.5215"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [164]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/best.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     25\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     27\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     28\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, filepath\u001b[38;5;241m=\u001b[39mcheckpoint_path, \n\u001b[1;32m     29\u001b[0m                                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m ]\n\u001b[0;32m---> 32\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpair1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpair2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_shape = data.shape[1:]\n",
    "\n",
    "# model = build_model(\n",
    "#     input_shape,\n",
    "#     head_size=256,\n",
    "#     num_heads=4,\n",
    "#     ff_dim=4,\n",
    "#     num_transformer_blocks=4,\n",
    "#     mlp_units=[128],\n",
    "#     mlp_dropout=0.4,\n",
    "#     dropout=0.25,\n",
    "# )\n",
    "\n",
    "model.compile(\n",
    "    loss={'classification': 'sparse_categorical_crossentropy', \n",
    "          'regression': 'mean_squared_error'},\n",
    "    loss_weights={'classification': 1.0, 'regression': 1.0},\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    metrics={'classification': 'sparse_categorical_accuracy', 'regression': 'mean_absolute_error'},\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "checkpoint_path = 'models/best.h5'\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.5, patience=3, min_lr=0.000001, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(monitor='val_loss', mode='min', filepath=checkpoint_path, \n",
    "                                    verbose=1, save_best_only=True, save_weights_only=False)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    [data[pair1], data[pair2]],\n",
    "    [labels, labels / 2],\n",
    "    validation_split=0.15,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair1_test = np.array(pair1_, dtype=int)[10000:15000]\n",
    "pair2_test = np.array(pair2_, dtype=int)[10000:15000]\n",
    "labels_test = np.array(labels_, dtype=int)[10000:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 78s 473ms/step - loss: 1.3376 - classification_loss: 0.9875 - regression_loss: 0.3501 - classification_sparse_categorical_accuracy: 0.5612 - regression_mean_absolute_error: 0.4904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3376017808914185,\n",
       " 0.9875016808509827,\n",
       " 0.35010001063346863,\n",
       " 0.5612000226974487,\n",
       " 0.4904000163078308]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "    [data[pair1_test], data[pair2_test]],\n",
    "    [labels_test, labels_test / 2], \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_unique = train.iloc[pair1_test].Filename.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"377\" value=\"377\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">375/377</span>\n",
       "<span class=\"Time-label\">[02:59<00:00, 0.47s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [] 377/377 [02:59<00:00, 0.47s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_preds = []\n",
    "regr_preds = []\n",
    "\n",
    "for filename in track(filenames_unique):\n",
    "    \n",
    "    indxs = np.where(pd.Series(pair1_test).isin(train[train.Filename == filename].index.values))[0]\n",
    "    preds = model.predict([data[pair1_test[indxs]], data[pair2_test[indxs]]])\n",
    "    class_pred = np.mean(preds[0], axis=0)\n",
    "    class_pred = np.where(class_pred == class_pred.max())[0][0]\n",
    "    regr_pred = np.mean(preds[1])\n",
    "    \n",
    "    class_preds.append(class_pred)\n",
    "    regr_preds.append(regr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.19635858, 0.5662945 , 0.23734692],\n",
       "        [0.19532153, 0.56761634, 0.23706213],\n",
       "        [0.20203047, 0.56013244, 0.23783715],\n",
       "        [0.20056798, 0.56482655, 0.23460552]], dtype=float32),\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32)]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17642\n",
       "2     7028\n",
       "0     6713\n",
       "Name: Class_label, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Class_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    \n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    \n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = inputs\n",
    "        \n",
    "    x = layers.Conv1D(32, 3, activation='relu')(x)\n",
    "    x = layers.Conv1D(16, 3, activation='relu')(x)\n",
    "    x = layers.Conv1D(8, 3, activation='relu')(x)\n",
    "    x = layers.AveragePooling1D()(x)\n",
    "    \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    \n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    \n",
    "    output1 = layers.Dense(3, activation=\"softmax\", name='classification')(x)\n",
    "    \n",
    "    return keras.Model(inputs, output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4685, 720, 14)"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 04:25:11.560330: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 0s - loss: 192.4748 - sparse_categorical_accuracy: 0.4714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 04:32:17.581056: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.01018, saving model to models/classification_best.h5\n",
      "63/63 [==============================] - 461s 7s/step - loss: 192.4748 - sparse_categorical_accuracy: 0.4714 - val_loss: 1.0102 - val_sparse_categorical_accuracy: 0.5434 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0326 - sparse_categorical_accuracy: 0.5221\n",
      "Epoch 2: val_loss did not improve from 1.01018\n",
      "63/63 [==============================] - 415s 7s/step - loss: 1.0326 - sparse_categorical_accuracy: 0.5221 - val_loss: 1.0185 - val_sparse_categorical_accuracy: 0.5434 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0279 - sparse_categorical_accuracy: 0.5372 \n",
      "Epoch 3: val_loss did not improve from 1.01018\n",
      "63/63 [==============================] - 2895s 47s/step - loss: 1.0279 - sparse_categorical_accuracy: 0.5372 - val_loss: 1.0148 - val_sparse_categorical_accuracy: 0.5434 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0266 - sparse_categorical_accuracy: 0.5414\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.01018\n",
      "63/63 [==============================] - 417s 7s/step - loss: 1.0266 - sparse_categorical_accuracy: 0.5414 - val_loss: 1.0120 - val_sparse_categorical_accuracy: 0.5434 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0204 - sparse_categorical_accuracy: 0.5432  \n",
      "Epoch 5: val_loss did not improve from 1.01018\n",
      "63/63 [==============================] - 7301s 118s/step - loss: 1.0204 - sparse_categorical_accuracy: 0.5432 - val_loss: 1.0220 - val_sparse_categorical_accuracy: 0.5434 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0229 - sparse_categorical_accuracy: 0.5432\n",
      "Epoch 6: val_loss did not improve from 1.01018\n",
      "63/63 [==============================] - 445s 7s/step - loss: 1.0229 - sparse_categorical_accuracy: 0.5432 - val_loss: 1.0109 - val_sparse_categorical_accuracy: 0.5434 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0208 - sparse_categorical_accuracy: 0.5427\n",
      "Epoch 7: val_loss improved from 1.01018 to 1.00663, saving model to models/classification_best.h5\n",
      "63/63 [==============================] - 428s 7s/step - loss: 1.0208 - sparse_categorical_accuracy: 0.5427 - val_loss: 1.0066 - val_sparse_categorical_accuracy: 0.5434 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0142 - sparse_categorical_accuracy: 0.5432\n",
      "Epoch 8: val_loss improved from 1.00663 to 1.00654, saving model to models/classification_best.h5\n",
      "63/63 [==============================] - 464s 7s/step - loss: 1.0142 - sparse_categorical_accuracy: 0.5432 - val_loss: 1.0065 - val_sparse_categorical_accuracy: 0.5434 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0189 - sparse_categorical_accuracy: 0.5429\n",
      "Epoch 9: val_loss did not improve from 1.00654\n",
      "63/63 [==============================] - 473s 8s/step - loss: 1.0189 - sparse_categorical_accuracy: 0.5429 - val_loss: 1.0070 - val_sparse_categorical_accuracy: 0.5434 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0175 - sparse_categorical_accuracy: 0.5424\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.00654\n",
      "63/63 [==============================] - 445s 7s/step - loss: 1.0175 - sparse_categorical_accuracy: 0.5424 - val_loss: 1.0138 - val_sparse_categorical_accuracy: 0.5434 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0194 - sparse_categorical_accuracy: 0.5424\n",
      "Epoch 11: val_loss improved from 1.00654 to 1.00652, saving model to models/classification_best.h5\n",
      "63/63 [==============================] - 426s 7s/step - loss: 1.0194 - sparse_categorical_accuracy: 0.5424 - val_loss: 1.0065 - val_sparse_categorical_accuracy: 0.5434 - lr: 2.5000e-05\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0182 - sparse_categorical_accuracy: 0.5427\n",
      "Epoch 12: val_loss improved from 1.00652 to 1.00610, saving model to models/classification_best.h5\n",
      "63/63 [==============================] - 474s 8s/step - loss: 1.0182 - sparse_categorical_accuracy: 0.5427 - val_loss: 1.0061 - val_sparse_categorical_accuracy: 0.5434 - lr: 2.5000e-05\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [720]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/classification_best.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     23\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     24\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     25\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     26\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, filepath\u001b[38;5;241m=\u001b[39mcheckpoint_path, \n\u001b[1;32m     27\u001b[0m                                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m ]\n\u001b[0;32m---> 30\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_shape = data.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics='sparse_categorical_accuracy',\n",
    ")\n",
    "# model.summary()\n",
    "\n",
    "checkpoint_path = 'models/classification_best.h5'\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.5, patience=3, min_lr=0.000001, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(monitor='val_loss', mode='min', filepath=checkpoint_path, \n",
    "                                    verbose=1, save_best_only=True, save_weights_only=False)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    data,\n",
    "    labels,\n",
    "    validation_split=0.15,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('dataset_train.xlsx')\n",
    "test.Data = test.Data.apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "test.Data_2 = test.Data_2.apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "test['idx'] = list(test.index)\n",
    "test_sequences = test.groupby(['Filename', 'Test_index', 'Presentation']).idx.unique().reset_index()\n",
    "\n",
    "sample_ = []\n",
    "sample_idxs = []\n",
    "\n",
    "for i in range(train_sequences.shape[0]):\n",
    "    for j in train_sequences.idx.iloc[i]:\n",
    "        indexes_ = np.random.choice(len(train_sequences.idx.iloc[i]), 3)\n",
    "        sample_.append(j)\n",
    "        sample_idxs.append(train_sequences.idx.iloc[i][indexes_])\n",
    "\n",
    "data1 = []\n",
    "for idx in sample_idxs:\n",
    "    temp = np.concatenate(test.Data.iloc[idx].values, axis=0)\n",
    "    if len(temp) < 720:\n",
    "        fill_temp = np.zeros((720-len(temp)))\n",
    "        fill_temp[...] = np.mean(temp)\n",
    "        temp = np.hstack([temp, fill_temp])\n",
    "    data1.append(temp)\n",
    "    \n",
    "data2 = []\n",
    "for idx in sample_idxs:\n",
    "    temp = np.concatenate(test.Data_2.iloc[idx].values, axis=0)\n",
    "    if len(temp) < 720:\n",
    "        fill_temp = np.zeros((720-len(temp)))\n",
    "        fill_temp[...] = np.mean(temp)\n",
    "        temp = np.hstack([temp, fill_temp])\n",
    "    data2.append(temp)\n",
    "\n",
    "data1 = np.concatenate(data1).reshape((len(data1), 720))\n",
    "data2 = np.concatenate(data2).reshape((len(data1), 720))\n",
    "data = np.concatenate([data1[..., np.newaxis], data2[..., np.newaxis]], axis=2)\n",
    "\n",
    "data1_cumsum = np.cumsum(data1, axis=1)\n",
    "data2_cumsum = np.cumsum(data2, axis=1)\n",
    "\n",
    "deriv_shifts = [3, 7, 15, 31, 63]\n",
    "derivs1 = []\n",
    "\n",
    "for ds in deriv_shifts:\n",
    "\n",
    "    deriv = data1[:, :-ds] - data1[:, ds:]\n",
    "    values_to_fill = data1.shape[1] - deriv.shape[1]\n",
    "    deriv = np.hstack([deriv, np.zeros((data1.shape[0], values_to_fill))])\n",
    "    \n",
    "    derivs1.append(deriv)\n",
    "    \n",
    "deriv_shifts = [3, 7, 15, 31, 63]\n",
    "derivs2 = []\n",
    "\n",
    "for ds in deriv_shifts:\n",
    "\n",
    "    deriv = data2[:, :-ds] - data2[:, ds:]\n",
    "    values_to_fill = data2.shape[1] - deriv.shape[1]\n",
    "    deriv = np.hstack([deriv, np.zeros((data2.shape[0], values_to_fill))])\n",
    "    \n",
    "    derivs2.append(deriv)\n",
    "    \n",
    "data = np.concatenate([\n",
    "    data,\n",
    "    data1_cumsum[..., np.newaxis],\n",
    "    data2_cumsum[..., np.newaxis],\n",
    "], axis=2)\n",
    "\n",
    "for deriv in derivs1:\n",
    "    data = np.concatenate([\n",
    "        data,\n",
    "        deriv[..., np.newaxis],\n",
    "    ], axis=2)\n",
    "    \n",
    "for deriv in derivs2:\n",
    "    data = np.concatenate([\n",
    "        data,\n",
    "        deriv[..., np.newaxis],\n",
    "    ], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31383, 720, 14)"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 08:33:31.691862: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_binary = []\n",
    "for pred in test_preds:\n",
    "    test_preds_binary.append(np.where(pred == pred.max())[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Class_label'] = test_preds_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(' .csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
